{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-BDLSTM_M2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guott3kGTrxa",
        "outputId": "c7b07fba-1d2a-485f-94f4-1a5de6d52228"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOnWJ1hrEDYz"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras import initializers, regularizers, optimizers, layers\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OArVbJGpFtsE"
      },
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=5000,MAX_SEQUENCE_LENGTH=200):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    embeddings_index = {}\n",
        "    with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Glove', 'glove.6B.100d.txt')) as f:\n",
        "      for line in f:\n",
        "          values = line.split()\n",
        "          word = values[0]\n",
        "          try:\n",
        "              coefs = np.asarray(values[1:], dtype='float32')\n",
        "          except:\n",
        "             pass\n",
        "          embeddings_index[word] = coefs\n",
        "      f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    return (X_train, X_test, word_index,embeddings_index)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8lZ3R3_Ge5y"
      },
      "source": [
        "def Build_Model_RCNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=200, EMBEDDING_DIM=100):\n",
        "\n",
        "    kernel_size = 5\n",
        "    filters = 100\n",
        "    pool_size = 4\n",
        "    gru_node = 128\n",
        "\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
        "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
        "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False))\n",
        "    model.add(Conv1D(filters=100, kernel_size=5,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=4))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.3,recurrent_dropout=0.5)))\n",
        "    #model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.4,recurrent_dropout=0.5)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(units=512, activation=\"relu\",\n",
        "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "    model.add(Dropout(rate=0.4))\n",
        "    model.add(Dense(7, activation=\"softmax\"))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\")\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAB1J1yBqcCk"
      },
      "source": [
        "def get_data_train():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/trainset1.csv')\n",
        "  df.head()\n",
        "  X=df['body']\n",
        "  Y = df['intent_2'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  Y = to_categorical(Y_nids, num_classes=7)\n",
        "  return X, Y"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYQz5eHMft58"
      },
      "source": [
        " df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data.csv')\n",
        " df.head()\n",
        " X_1 = df['body']"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uts74FvlRwJq"
      },
      "source": [
        "def get_data_test():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data.csv')\n",
        "  df.head()\n",
        "  X_t = df['body']\n",
        "  Y = df['intent_2'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  y_t = to_categorical(Y_nids, num_classes=7)\n",
        "  return X_t, y_t\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt4R19XuGsx0",
        "outputId": "3df53ce3-adc0-4fb1-e8e0-fcf34d34caa2"
      },
      "source": [
        "X_train,y_train= get_data_train()\n",
        "X_val,y_val= get_data_test()\n",
        "X_train,X_val, word_index, embeddings_index = loadData_Tokenizer(X_train,X_val)\n",
        "nclasses=7\n",
        "\n",
        "model_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, nclasses)\n",
        "\n",
        "\n",
        "model_RCNN.summary()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 777 unique tokens.\n",
            "(566, 200)\n",
            "Total 400000 word vectors.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 100)          77800     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 200, 100)          50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 50, 256)           234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 497,571\n",
            "Trainable params: 419,771\n",
            "Non-trainable params: 77,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujDz5F_iGx6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fd291c-9e9e-4474-eb77-8876424c546d"
      },
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "model_RCNN.fit(X_train, y_train,\n",
        "                              validation_data=(X_val,y_val),\n",
        "                              epochs=40,\n",
        "                              batch_size=64,\n",
        "                              verbose=2, callbacks=[checkpointer])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/40\n",
            "9/9 - 10s - loss: 2.0540 - accuracy: 0.1467 - val_loss: 1.9990 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.99896, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 2/40\n",
            "9/9 - 4s - loss: 2.0051 - accuracy: 0.2336 - val_loss: 1.9868 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.99896 to 1.98685, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 3/40\n",
            "9/9 - 4s - loss: 1.9725 - accuracy: 0.2413 - val_loss: 1.9685 - val_accuracy: 0.2083\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.98685 to 1.96847, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 4/40\n",
            "9/9 - 4s - loss: 1.9323 - accuracy: 0.2529 - val_loss: 1.9225 - val_accuracy: 0.2292\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.96847 to 1.92249, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 5/40\n",
            "9/9 - 4s - loss: 1.8856 - accuracy: 0.2741 - val_loss: 1.8790 - val_accuracy: 0.4167\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.92249 to 1.87898, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 6/40\n",
            "9/9 - 4s - loss: 1.8286 - accuracy: 0.2876 - val_loss: 1.8708 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.87898 to 1.87078, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 7/40\n",
            "9/9 - 4s - loss: 1.7882 - accuracy: 0.3050 - val_loss: 1.8203 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.87078 to 1.82028, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 8/40\n",
            "9/9 - 4s - loss: 1.7752 - accuracy: 0.2992 - val_loss: 1.8479 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.82028\n",
            "Epoch 9/40\n",
            "9/9 - 4s - loss: 1.7154 - accuracy: 0.3494 - val_loss: 1.7698 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.82028 to 1.76980, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 10/40\n",
            "9/9 - 4s - loss: 1.7061 - accuracy: 0.3224 - val_loss: 1.7833 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.76980\n",
            "Epoch 11/40\n",
            "9/9 - 4s - loss: 1.6751 - accuracy: 0.3494 - val_loss: 1.7501 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.76980 to 1.75013, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 12/40\n",
            "9/9 - 4s - loss: 1.6459 - accuracy: 0.3456 - val_loss: 1.7189 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.75013 to 1.71889, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 13/40\n",
            "9/9 - 4s - loss: 1.5973 - accuracy: 0.4305 - val_loss: 1.7002 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.71889 to 1.70025, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 14/40\n",
            "9/9 - 4s - loss: 1.5614 - accuracy: 0.4131 - val_loss: 1.6454 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.70025 to 1.64543, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 15/40\n",
            "9/9 - 4s - loss: 1.5085 - accuracy: 0.4556 - val_loss: 1.6422 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.64543 to 1.64220, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 16/40\n",
            "9/9 - 4s - loss: 1.4807 - accuracy: 0.4768 - val_loss: 1.6048 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.64220 to 1.60482, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 17/40\n",
            "9/9 - 4s - loss: 1.4638 - accuracy: 0.4788 - val_loss: 1.4939 - val_accuracy: 0.4792\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.60482 to 1.49387, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 18/40\n",
            "9/9 - 4s - loss: 1.4262 - accuracy: 0.4691 - val_loss: 1.5789 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.49387\n",
            "Epoch 19/40\n",
            "9/9 - 4s - loss: 1.3852 - accuracy: 0.5212 - val_loss: 1.4579 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.49387 to 1.45792, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 20/40\n",
            "9/9 - 4s - loss: 1.2992 - accuracy: 0.5560 - val_loss: 1.4601 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.45792\n",
            "Epoch 21/40\n",
            "9/9 - 4s - loss: 1.2886 - accuracy: 0.5483 - val_loss: 1.3871 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.45792 to 1.38707, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 22/40\n",
            "9/9 - 4s - loss: 1.2002 - accuracy: 0.6139 - val_loss: 1.3769 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.38707 to 1.37694, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 23/40\n",
            "9/9 - 4s - loss: 1.1970 - accuracy: 0.5830 - val_loss: 1.3468 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.37694 to 1.34680, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 24/40\n",
            "9/9 - 4s - loss: 1.1492 - accuracy: 0.5985 - val_loss: 1.3952 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.34680\n",
            "Epoch 25/40\n",
            "9/9 - 4s - loss: 1.0902 - accuracy: 0.6313 - val_loss: 1.3230 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.34680 to 1.32304, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 26/40\n",
            "9/9 - 4s - loss: 1.0576 - accuracy: 0.6660 - val_loss: 1.2791 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.32304 to 1.27909, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 27/40\n",
            "9/9 - 4s - loss: 1.0121 - accuracy: 0.6795 - val_loss: 1.2914 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.27909\n",
            "Epoch 28/40\n",
            "9/9 - 4s - loss: 0.9586 - accuracy: 0.6795 - val_loss: 1.2640 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.27909 to 1.26399, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 29/40\n",
            "9/9 - 4s - loss: 0.9368 - accuracy: 0.7008 - val_loss: 1.2393 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.26399 to 1.23929, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 30/40\n",
            "9/9 - 4s - loss: 0.8549 - accuracy: 0.7471 - val_loss: 1.2455 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.23929\n",
            "Epoch 31/40\n",
            "9/9 - 4s - loss: 0.8343 - accuracy: 0.7587 - val_loss: 1.2526 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.23929\n",
            "Epoch 32/40\n",
            "9/9 - 4s - loss: 0.7884 - accuracy: 0.7838 - val_loss: 1.2194 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.23929 to 1.21944, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 33/40\n",
            "9/9 - 4s - loss: 0.7641 - accuracy: 0.7915 - val_loss: 1.2892 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.21944\n",
            "Epoch 34/40\n",
            "9/9 - 4s - loss: 0.7417 - accuracy: 0.7896 - val_loss: 1.1815 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.21944 to 1.18147, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/weights.hdf5\n",
            "Epoch 35/40\n",
            "9/9 - 4s - loss: 0.7103 - accuracy: 0.8012 - val_loss: 1.3726 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.18147\n",
            "Epoch 36/40\n",
            "9/9 - 4s - loss: 0.6810 - accuracy: 0.7915 - val_loss: 1.2120 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.18147\n",
            "Epoch 37/40\n",
            "9/9 - 4s - loss: 0.6168 - accuracy: 0.8301 - val_loss: 1.3116 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.18147\n",
            "Epoch 38/40\n",
            "9/9 - 4s - loss: 0.5669 - accuracy: 0.8591 - val_loss: 1.2846 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.18147\n",
            "Epoch 39/40\n",
            "9/9 - 4s - loss: 0.5453 - accuracy: 0.8591 - val_loss: 1.2597 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.18147\n",
            "Epoch 40/40\n",
            "9/9 - 4s - loss: 0.5116 - accuracy: 0.8571 - val_loss: 1.3523 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.18147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d521b3250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBUMg9jpb4u"
      },
      "source": [
        "#score, acc = model_RCNN.evaluate(X_test,y_test\n",
        "#                            ,batch_size=128)\n",
        "#print('Test accuracy with charcrnn:', acc)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1JrFDf38SLW",
        "outputId": "220e42e1-bcbd-48a1-e42f-c30881a3ad87"
      },
      "source": [
        "model_RCNN.save('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/saved_model/my_models1')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/saved_model/my_models1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZnSdpdG4yT"
      },
      "source": [
        "predicted = model_RCNN.predict(X_val)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_VoXCPRTDV"
      },
      "source": [
        "predicted = np.argmax(predicted, axis=1)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-09qtFOW0L"
      },
      "source": [
        " target_names = ['Dependencies between design parameters',\n",
        "       'Effects of design parameters on objectives',\n",
        "       'Exploration of design parameter values', 'Monitoring objective values',\n",
        "       'NAN', 'Selected design parameter values for objective(s)',\n",
        "       'Tradeoff between objectives']"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Ubc6HjQaM6",
        "outputId": "24f2fbc4-0ab4-46da-de4b-5bed6303d46a"
      },
      "source": [
        "print(metrics.classification_report(np.argmax(y_val, axis=1), predicted , target_names=target_names))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   precision    recall  f1-score   support\n",
            "\n",
            "           Dependencies between design parameters       1.00      0.60      0.75         5\n",
            "       Effects of design parameters on objectives       0.50      0.60      0.55        10\n",
            "           Exploration of design parameter values       0.83      0.62      0.71         8\n",
            "                      Monitoring objective values       0.42      0.71      0.53         7\n",
            "                                              NAN       0.89      0.80      0.84        10\n",
            "Selected design parameter values for objective(s)       1.00      0.25      0.40         4\n",
            "                      Tradeoff between objectives       0.60      0.75      0.67         4\n",
            "\n",
            "                                         accuracy                           0.65        48\n",
            "                                        macro avg       0.75      0.62      0.63        48\n",
            "                                     weighted avg       0.73      0.65      0.65        48\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJDIP-CRmtC"
      },
      "source": [
        "ans= np.array(['Dependencies between design parameters',\n",
        "       'Effects of design parameters on objectives',\n",
        "       'Exploration of design parameter values', 'Monitoring objective values',\n",
        "       'NAN', 'Selected design parameter values for objective(s)',\n",
        "       'Tradeoff between objectives'])[predicted ]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLTvTL6CGnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9366f1d-ed5b-4be7-dbb1-bc2884d8823a"
      },
      "source": [
        "for x, y in zip(X_1, ans):\n",
        "  print(\"Chat body: \",x)\n",
        "  print(\"Predicted intent: \", y, \"\\n\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chat body:  My design depends on the piston diameter, what happens if you decrease it? \n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Does increasing the flywheel thickness increase or decrease \"c\"?\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  That is what my document specifies. I will keep c low unless the piston needs it to be higher\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  thats if D = 45 where D is the piston bore diameter\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Does the flywheel shaft diameter \"ds\" affect any variables in your control?\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  But if i increase the thickness i could make it a lot higher\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Increasing the offset increases the mass and decreases the factor of safety.\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  Whats the effect of D on your results?\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  can increase diameter is we need higher fos\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Lower D, lowers my mass and FOS\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  whoever changed please go back\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  the 2.95 design also has the lowest mass\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  If that reduces your fos\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  no because it went down to fair, the mass went up a lot\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Have you changed the system at all? Our quality has dropped.\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  is there a bore diameter you are set on? or are you still experimenting?\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  I just got my mass down to 0.11\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  I am getting around 2.26-2.95\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  Make sure you dont drop too much mass though\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  is that best case or worst case? my numbers are in the hundreds so we can play with ds if you use that\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  do you think I should try and increase those?\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  tf = 10 mm; ds = 25 mm;\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  we should try a safe configuration and trim weight from there\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  we have excellent quality right now\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  i think we have excellent quality right now\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  Rn were under mass so if you need to you could increase it a bit\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  Right now our factor of safety is chilling around 2.5\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  I'm still seeing 'poor' on my end\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  we're only trying to keep FOS over 2 right?\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  what range of fos #s are you getting? mine are in the hundreds so it's not the limiting system\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Yeah, that was nice\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  we're back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  ya'' should chat about that\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  alright, guess not then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  okay\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  alright, guess no then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  before uploading any new broadcasts copy and paste a message into all your chats so we know its changing\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Mine should be broadcasting\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  27\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  any FOS higher than 2 gets us nothing more, we need to drop mass\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  If I reduce my mass by .03, it reduces FOS by .25 to 1.76\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  I now have minimum fos but i further decreased my mass\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Can you cut any more mass out and get closer to FOS  = 2\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  I think I optimized mine as well my mass is at 0.10 and fos is 2.77\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  for tf = 10 & ds = 25; m = 0.55 and FOS = 5625.56\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n",
            "Chat body:  the current broadcast. FOS = 5626\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  tf = 10, ds = 25\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}