{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAR CNN-BDLSTM_M2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guott3kGTrxa",
        "outputId": "8bfad204-3c68-4794-ed8b-f0a6a5802368"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOnWJ1hrEDYz"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras import initializers, regularizers, optimizers, layers\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OArVbJGpFtsE"
      },
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_chars=150,MAX_SEQUENCE_LENGTH=200):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "\n",
        "    alphabet=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "    char_dict = {}\n",
        "    for i, char in enumerate(alphabet):\n",
        "      char_dict[char] = i + 1\n",
        "    \n",
        "    print(\"characters of the dictionary are  \")\n",
        "    print(char_dict)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_chars, char_level=True, oov_token='UNK')\n",
        "    # Use char_dict to replace the tk.word_index\n",
        "    tokenizer.word_index = char_dict \n",
        "    # Add 'UNK' to the vocabulary \n",
        "    tokenizer.word_index[tokenizer.oov_token] = max(char_dict.values()) + 1\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    vocab_size = len(tokenizer.word_index)+1\n",
        "\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    return (X_train, X_test, word_index,vocab_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8lZ3R3_Ge5y"
      },
      "source": [
        "def Build_Model_RCNN_Text(word_index, nclasses, VS, MAX_SEQUENCE_LENGTH=200, EMBEDDING_DIM=100):\n",
        "\n",
        "    kernel_size = 5\n",
        "    filters = 100\n",
        "    pool_size = 4\n",
        "    gru_node = 128\n",
        "\n",
        "    embed_size = EMBEDDING_DIM\n",
        "    embedding_layer = Embedding(VS, embed_size, input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Conv1D(filters=100, kernel_size=5,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=4))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.3,recurrent_dropout=0.5)))\n",
        "    #model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.4,recurrent_dropout=0.5)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(units=512, activation=\"relu\",\n",
        "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "    model.add(Dropout(rate=0.4))\n",
        "    model.add(Dense(7, activation=\"softmax\"))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-7,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\")\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAB1J1yBqcCk"
      },
      "source": [
        "def get_data_train():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/trainset1.csv')\n",
        "  df.head()\n",
        "  X=df['body']\n",
        "  Y = df['intent_2'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  Y = to_categorical(Y_nids, num_classes=7)\n",
        "  return X, Y"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uts74FvlRwJq"
      },
      "source": [
        "def get_data_test():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data.csv')\n",
        "  df.head()\n",
        "  X_t = df['body']\n",
        "  Y = df['intent_2'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  y_t = to_categorical(Y_nids, num_classes=7)\n",
        "  return X_t, y_t\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt4R19XuGsx0",
        "outputId": "622bd3da-9d08-46dd-efde-1fe112b4ee9d"
      },
      "source": [
        "#X_train, X_test1, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train,y_train= get_data_train()\n",
        "X_val,y_val= get_data_test()\n",
        "X_train,X_val, word_index, vocab_size = loadData_Tokenizer(X_train,X_val)\n",
        "nclasses=7\n",
        "\n",
        "model_CharRCNN2 = Build_Model_RCNN_Text(word_index, nclasses,vocab_size)\n",
        "\n",
        "\n",
        "model_CharRCNN2.summary()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "characters of the dictionary are  \n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, '0': 53, '1': 54, '2': 55, '3': 56, '4': 57, '5': 58, '6': 59, '7': 60, '8': 61, '9': 62, '-': 86, ',': 64, ';': 65, '.': 66, '!': 67, '?': 68, ':': 69, \"'\": 70, '\"': 71, '/': 72, '\\\\': 73, '|': 74, '_': 75, '@': 76, '#': 77, '$': 78, '%': 79, '^': 80, '&': 81, '*': 82, '~': 83, '`': 84, '+': 85, '=': 87, '<': 88, '>': 89, '(': 90, ')': 91, '[': 92, ']': 93, '{': 94, '}': 95}\n",
            "Found 57 unique tokens.\n",
            "(566, 200)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 200, 100)          5800      \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 200, 100)          50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 50, 256)           234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 425,571\n",
            "Trainable params: 425,571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujDz5F_iGx6m",
        "outputId": "4e17c683-852e-461b-a55a-42007ffd0f1c"
      },
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "model_CharRCNN2.fit(X_train, y_train,\n",
        "                              validation_data=(X_val,y_val),\n",
        "                              epochs=40,\n",
        "                              batch_size=32,\n",
        "                              verbose=2, callbacks=[checkpointer])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/40\n",
            "17/17 - 10s - loss: 2.0304 - accuracy: 0.1969 - val_loss: 2.0213 - val_accuracy: 0.2083\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.02131, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 2/40\n",
            "17/17 - 5s - loss: 2.0106 - accuracy: 0.1873 - val_loss: 1.9948 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.02131 to 1.99480, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 3/40\n",
            "17/17 - 5s - loss: 1.9349 - accuracy: 0.2664 - val_loss: 1.9325 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.99480 to 1.93248, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 4/40\n",
            "17/17 - 5s - loss: 1.8132 - accuracy: 0.2876 - val_loss: 1.8926 - val_accuracy: 0.2917\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.93248 to 1.89261, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 5/40\n",
            "17/17 - 5s - loss: 1.7839 - accuracy: 0.2973 - val_loss: 1.8184 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.89261 to 1.81838, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 6/40\n",
            "17/17 - 5s - loss: 1.7399 - accuracy: 0.3012 - val_loss: 1.8096 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.81838 to 1.80959, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 7/40\n",
            "17/17 - 5s - loss: 1.7573 - accuracy: 0.2896 - val_loss: 1.7907 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.80959 to 1.79068, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 8/40\n",
            "17/17 - 5s - loss: 1.7102 - accuracy: 0.3243 - val_loss: 1.8042 - val_accuracy: 0.2917\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.79068\n",
            "Epoch 9/40\n",
            "17/17 - 5s - loss: 1.7266 - accuracy: 0.3243 - val_loss: 1.7744 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.79068 to 1.77437, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 10/40\n",
            "17/17 - 5s - loss: 1.6933 - accuracy: 0.3301 - val_loss: 1.7299 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.77437 to 1.72988, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 11/40\n",
            "17/17 - 5s - loss: 1.6659 - accuracy: 0.3127 - val_loss: 1.7305 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.72988\n",
            "Epoch 12/40\n",
            "17/17 - 5s - loss: 1.6577 - accuracy: 0.3243 - val_loss: 1.7457 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.72988\n",
            "Epoch 13/40\n",
            "17/17 - 5s - loss: 1.6422 - accuracy: 0.3629 - val_loss: 1.6945 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.72988 to 1.69451, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 14/40\n",
            "17/17 - 5s - loss: 1.6338 - accuracy: 0.3320 - val_loss: 1.7053 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.69451\n",
            "Epoch 15/40\n",
            "17/17 - 5s - loss: 1.6319 - accuracy: 0.3649 - val_loss: 1.6902 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.69451 to 1.69018, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 16/40\n",
            "17/17 - 5s - loss: 1.6065 - accuracy: 0.3687 - val_loss: 1.7234 - val_accuracy: 0.2708\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.69018\n",
            "Epoch 17/40\n",
            "17/17 - 5s - loss: 1.5718 - accuracy: 0.3533 - val_loss: 1.7303 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.69018\n",
            "Epoch 18/40\n",
            "17/17 - 5s - loss: 1.5729 - accuracy: 0.3861 - val_loss: 1.7067 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.69018\n",
            "Epoch 19/40\n",
            "17/17 - 5s - loss: 1.5248 - accuracy: 0.3803 - val_loss: 1.7755 - val_accuracy: 0.2708\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.69018\n",
            "Epoch 20/40\n",
            "17/17 - 5s - loss: 1.5086 - accuracy: 0.3900 - val_loss: 1.8529 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.69018\n",
            "Epoch 21/40\n",
            "17/17 - 5s - loss: 1.4727 - accuracy: 0.4054 - val_loss: 1.8436 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.69018\n",
            "Epoch 22/40\n",
            "17/17 - 5s - loss: 1.4652 - accuracy: 0.4228 - val_loss: 1.7798 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.69018\n",
            "Epoch 23/40\n",
            "17/17 - 5s - loss: 1.4662 - accuracy: 0.4382 - val_loss: 1.7705 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.69018\n",
            "Epoch 24/40\n",
            "17/17 - 5s - loss: 1.4306 - accuracy: 0.4382 - val_loss: 1.8050 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.69018\n",
            "Epoch 25/40\n",
            "17/17 - 5s - loss: 1.4019 - accuracy: 0.4537 - val_loss: 1.8172 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.69018\n",
            "Epoch 26/40\n",
            "17/17 - 5s - loss: 1.3999 - accuracy: 0.4846 - val_loss: 1.8201 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.69018\n",
            "Epoch 27/40\n",
            "17/17 - 5s - loss: 1.3755 - accuracy: 0.4846 - val_loss: 1.8143 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.69018\n",
            "Epoch 28/40\n",
            "17/17 - 5s - loss: 1.3575 - accuracy: 0.4865 - val_loss: 1.7796 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.69018\n",
            "Epoch 29/40\n",
            "17/17 - 5s - loss: 1.3308 - accuracy: 0.4942 - val_loss: 1.8233 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.69018\n",
            "Epoch 30/40\n",
            "17/17 - 5s - loss: 1.2772 - accuracy: 0.5444 - val_loss: 1.8644 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.69018\n",
            "Epoch 31/40\n",
            "17/17 - 5s - loss: 1.2920 - accuracy: 0.5000 - val_loss: 1.8467 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.69018\n",
            "Epoch 32/40\n",
            "17/17 - 5s - loss: 1.2545 - accuracy: 0.5212 - val_loss: 1.8851 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.69018\n",
            "Epoch 33/40\n",
            "17/17 - 5s - loss: 1.2602 - accuracy: 0.5290 - val_loss: 1.8443 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.69018\n",
            "Epoch 34/40\n",
            "17/17 - 5s - loss: 1.1957 - accuracy: 0.5598 - val_loss: 1.6892 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.69018 to 1.68922, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 35/40\n",
            "17/17 - 5s - loss: 1.1740 - accuracy: 0.5541 - val_loss: 1.8315 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.68922\n",
            "Epoch 36/40\n",
            "17/17 - 5s - loss: 1.1374 - accuracy: 0.5792 - val_loss: 1.7247 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.68922\n",
            "Epoch 37/40\n",
            "17/17 - 5s - loss: 1.0919 - accuracy: 0.5830 - val_loss: 1.7267 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.68922\n",
            "Epoch 38/40\n",
            "17/17 - 5s - loss: 1.0873 - accuracy: 0.6120 - val_loss: 1.7586 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.68922\n",
            "Epoch 39/40\n",
            "17/17 - 5s - loss: 1.0666 - accuracy: 0.6042 - val_loss: 1.9982 - val_accuracy: 0.3542\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.68922\n",
            "Epoch 40/40\n",
            "17/17 - 5s - loss: 1.1591 - accuracy: 0.5637 - val_loss: 1.6455 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.68922 to 1.64551, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f82c86210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBUMg9jpb4u"
      },
      "source": [
        "#score, acc = model_CharRCNN.evaluate(X_test,y_test\n",
        "#                            ,batch_size=128)\n",
        "#print('Test accuracy with charcrnn:', acc)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1JrFDf38SLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6056b5-04b2-4775-9c23-88e5015a46e4"
      },
      "source": [
        "model_CharRCNN2.save('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/model_CharCRNN/saved_model/my_modelCharm2')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/model_CharCRNN/saved_model/my_modelCharm2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZnSdpdG4yT"
      },
      "source": [
        "predicted = model_CharRCNN2.predict(X_val)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_VoXCPRTDV"
      },
      "source": [
        "predicted = np.argmax(predicted, axis=1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-09qtFOW0L"
      },
      "source": [
        " target_names = ['Dependencies between design parameters',\n",
        "       'Effects of design parameters on objectives',\n",
        "       'Exploration of design parameter values', 'Monitoring objective values',\n",
        "       'NAN', 'Selected design parameter values for objective(s)',\n",
        "       'Tradeoff between objectives']"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Ubc6HjQaM6",
        "outputId": "e007f2fb-75c7-41f4-cba6-f54725680e65"
      },
      "source": [
        "print(metrics.classification_report(np.argmax(y_val, axis=1), predicted , target_names=target_names))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   precision    recall  f1-score   support\n",
            "\n",
            "           Dependencies between design parameters       0.36      0.80      0.50         5\n",
            "       Effects of design parameters on objectives       0.27      0.30      0.29        10\n",
            "           Exploration of design parameter values       0.00      0.00      0.00         8\n",
            "                      Monitoring objective values       0.29      0.29      0.29         7\n",
            "                                              NAN       0.90      0.90      0.90        10\n",
            "Selected design parameter values for objective(s)       0.40      0.50      0.44         4\n",
            "                      Tradeoff between objectives       0.33      0.25      0.29         4\n",
            "\n",
            "                                         accuracy                           0.44        48\n",
            "                                        macro avg       0.37      0.43      0.39        48\n",
            "                                     weighted avg       0.38      0.44      0.40        48\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJDIP-CRmtC"
      },
      "source": [
        "ans= np.array(['Dependencies between design parameters',\n",
        "       'Effects of design parameters on objectives',\n",
        "       'Exploration of design parameter values', 'Monitoring objective values',\n",
        "       'NAN', 'Selected design parameter values for objective(s)',\n",
        "       'Tradeoff between objectives'])[predicted ]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLTvTL6CGnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef87d8e-5e65-4a41-ff08-127b64f43b51"
      },
      "source": [
        "for x, y in zip(X_t, ans):\n",
        "  print(\"Chat body: \",x)\n",
        "  print(\"Predicted intent: \", y, \"\\n\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chat body:  My design depends on the piston diameter, what happens if you decrease it? \n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Does increasing the flywheel thickness increase or decrease \"c\"?\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  That is what my document specifies. I will keep c low unless the piston needs it to be higher\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  thats if D = 45 where D is the piston bore diameter\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Does the flywheel shaft diameter \"ds\" affect any variables in your control?\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  But if i increase the thickness i could make it a lot higher\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Increasing the offset increases the mass and decreases the factor of safety.\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  Whats the effect of D on your results?\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  can increase diameter is we need higher fos\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Lower D, lowers my mass and FOS\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n",
            "Chat body:  whoever changed please go back\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  the 2.95 design also has the lowest mass\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  If that reduces your fos\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  no because it went down to fair, the mass went up a lot\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Have you changed the system at all? Our quality has dropped.\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  is there a bore diameter you are set on? or are you still experimenting?\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  I just got my mass down to 0.11\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  I am getting around 2.26-2.95\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  Make sure you dont drop too much mass though\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  is that best case or worst case? my numbers are in the hundreds so we can play with ds if you use that\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  do you think I should try and increase those?\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  tf = 10 mm; ds = 25 mm;\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n",
            "Chat body:  we should try a safe configuration and trim weight from there\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  we have excellent quality right now\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  i think we have excellent quality right now\n",
            "Predicted intent:  Exploration of design parameter values \n",
            "\n",
            "Chat body:  Rn were under mass so if you need to you could increase it a bit\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Right now our factor of safety is chilling around 2.5\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  I'm still seeing 'poor' on my end\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  we're only trying to keep FOS over 2 right?\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  what range of fos #s are you getting? mine are in the hundreds so it's not the limiting system\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Yeah, that was nice\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  we're back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  ya'' should chat about that\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  alright, guess not then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  okay\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  alright, guess no then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  before uploading any new broadcasts copy and paste a message into all your chats so we know its changing\n",
            "Predicted intent:  Dependencies between design parameters \n",
            "\n",
            "Chat body:  Mine should be broadcasting\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  27\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  any FOS higher than 2 gets us nothing more, we need to drop mass\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  If I reduce my mass by .03, it reduces FOS by .25 to 1.76\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n",
            "Chat body:  I now have minimum fos but i further decreased my mass\n",
            "Predicted intent:  Effects of design parameters on objectives \n",
            "\n",
            "Chat body:  Can you cut any more mass out and get closer to FOS  = 2\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  I think I optimized mine as well my mass is at 0.10 and fos is 2.77\n",
            "Predicted intent:  Tradeoff between objectives \n",
            "\n",
            "Chat body:  for tf = 10 & ds = 25; m = 0.55 and FOS = 5625.56\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n",
            "Chat body:  the current broadcast. FOS = 5626\n",
            "Predicted intent:  Monitoring objective values \n",
            "\n",
            "Chat body:  tf = 10, ds = 25\n",
            "Predicted intent:  Selected design parameter values for objective(s) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}