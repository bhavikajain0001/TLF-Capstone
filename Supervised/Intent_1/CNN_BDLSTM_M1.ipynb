{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-BDLSTM_M1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guott3kGTrxa",
        "outputId": "61bc5d7b-c53b-40e0-ebde-4f4230a58c39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOnWJ1hrEDYz"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras import initializers, regularizers, optimizers, layers\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OArVbJGpFtsE"
      },
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=5000,MAX_SEQUENCE_LENGTH=200):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    embeddings_index = {}\n",
        "    with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Glove', 'glove.6B.100d.txt')) as f:\n",
        "      for line in f:\n",
        "          values = line.split()\n",
        "          word = values[0]\n",
        "          try:\n",
        "              coefs = np.asarray(values[1:], dtype='float32')\n",
        "          except:\n",
        "             pass\n",
        "          embeddings_index[word] = coefs\n",
        "      f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    return (X_train, X_test, word_index,embeddings_index)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8lZ3R3_Ge5y"
      },
      "source": [
        "def Build_Model_RCNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=200, EMBEDDING_DIM=100):\n",
        "\n",
        "    kernel_size = 4\n",
        "    filters = 100\n",
        "    pool_size = 4\n",
        "    gru_node = 128\n",
        "\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
        "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
        "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False))\n",
        "    model.add(Conv1D(filters=100, kernel_size=5,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=4))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.3,recurrent_dropout=0.5)))\n",
        "    #model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.4,recurrent_dropout=0.5)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(units=512, activation=\"relu\",\n",
        "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "    model.add(Dropout(rate=0.4))\n",
        "    model.add(Dense(3, activation=\"softmax\"))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-7,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\")\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MbmBziSXghA"
      },
      "source": [
        "#df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/S3inital_final.csv')\n",
        "#df.head()\n",
        "#X=df['body']\n",
        "#Y = df['intent_1'].astype(\"category\")\n",
        "#cat_types= Y.cat.categories\n",
        "#Y_nids = Y.cat.codes\n",
        "#Y = to_categorical(Y_nids, num_classes=3)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAB1J1yBqcCk"
      },
      "source": [
        "def get_data_train():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/trainset_int1.csv')\n",
        "  df.head()\n",
        "  X=df['body']\n",
        "  Y = df['intent_1'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  Y = to_categorical(Y_nids, num_classes=3)\n",
        "  return X, Y"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uts74FvlRwJq"
      },
      "source": [
        "def get_data_test():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data_i1.csv')\n",
        "  df.head()\n",
        "  X_t = df['body']\n",
        "  Y = df['intent_1'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  y_t = to_categorical(Y_nids, num_classes=3)\n",
        "  return X_t, y_t\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWFY0Z-LA2e"
      },
      "source": [
        " df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data_i1.csv')\n",
        " df.head()\n",
        " X_1 = df['body']"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt4R19XuGsx0",
        "outputId": "69461bfd-9bf6-41c5-f8aa-4c81dd818fa3"
      },
      "source": [
        "#X_train, X_test1, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train,y_train= get_data_train()\n",
        "X_test1,y_test= get_data_test()\n",
        "X_train,X_val, word_index, embeddings_index = loadData_Tokenizer(X_train,X_test1)\n",
        "nclasses=3\n",
        "\n",
        "model_RCNNi1 = Build_Model_RCNN_Text(word_index,embeddings_index, nclasses)\n",
        "\n",
        "\n",
        "model_RCNNi1.summary()\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 776 unique tokens.\n",
            "(565, 200)\n",
            "Total 400000 word vectors.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 100)          77700     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 200, 100)          50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 50, 256)           234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 495,419\n",
            "Trainable params: 417,719\n",
            "Non-trainable params: 77,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujDz5F_iGx6m",
        "outputId": "f793e189-44e9-41d1-f24f-aa2a3312f423"
      },
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "model_RCNNi1.fit(X_train, y_train,\n",
        "                              validation_data=(X_val,y_test),\n",
        "                              epochs=30,\n",
        "                              batch_size=64,\n",
        "                              verbose=2, callbacks=[checkpointer])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/30\n",
            "9/9 - 10s - loss: 1.0494 - accuracy: 0.5629 - val_loss: 1.0136 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.01359, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 2/30\n",
            "9/9 - 4s - loss: 0.9859 - accuracy: 0.5919 - val_loss: 0.9865 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.01359 to 0.98655, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 3/30\n",
            "9/9 - 4s - loss: 0.9598 - accuracy: 0.5938 - val_loss: 0.9577 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.98655 to 0.95765, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 4/30\n",
            "9/9 - 4s - loss: 0.9266 - accuracy: 0.5938 - val_loss: 0.9324 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.95765 to 0.93239, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 5/30\n",
            "9/9 - 4s - loss: 0.9163 - accuracy: 0.5899 - val_loss: 0.9080 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.93239 to 0.90803, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 6/30\n",
            "9/9 - 4s - loss: 0.8952 - accuracy: 0.6035 - val_loss: 0.8890 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.90803 to 0.88897, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 7/30\n",
            "9/9 - 4s - loss: 0.8786 - accuracy: 0.6248 - val_loss: 0.8545 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.88897 to 0.85450, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 8/30\n",
            "9/9 - 4s - loss: 0.8437 - accuracy: 0.6422 - val_loss: 0.8237 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.85450 to 0.82371, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 9/30\n",
            "9/9 - 4s - loss: 0.8210 - accuracy: 0.6267 - val_loss: 0.7987 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.82371 to 0.79866, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 10/30\n",
            "9/9 - 4s - loss: 0.8068 - accuracy: 0.6809 - val_loss: 0.7774 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.79866 to 0.77743, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 11/30\n",
            "9/9 - 4s - loss: 0.7645 - accuracy: 0.7369 - val_loss: 0.7593 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.77743 to 0.75932, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 12/30\n",
            "9/9 - 4s - loss: 0.7387 - accuracy: 0.7157 - val_loss: 0.7285 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.75932 to 0.72853, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 13/30\n",
            "9/9 - 4s - loss: 0.7002 - accuracy: 0.7698 - val_loss: 0.7172 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.72853 to 0.71720, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 14/30\n",
            "9/9 - 4s - loss: 0.6744 - accuracy: 0.7485 - val_loss: 0.7588 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.71720\n",
            "Epoch 15/30\n",
            "9/9 - 4s - loss: 0.6549 - accuracy: 0.7621 - val_loss: 0.6921 - val_accuracy: 0.7708\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.71720 to 0.69215, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 16/30\n",
            "9/9 - 4s - loss: 0.6112 - accuracy: 0.7988 - val_loss: 0.6803 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.69215 to 0.68027, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 17/30\n",
            "9/9 - 4s - loss: 0.5864 - accuracy: 0.7988 - val_loss: 0.7459 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.68027\n",
            "Epoch 18/30\n",
            "9/9 - 4s - loss: 0.5713 - accuracy: 0.8027 - val_loss: 0.6640 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.68027 to 0.66402, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 19/30\n",
            "9/9 - 4s - loss: 0.5477 - accuracy: 0.8279 - val_loss: 0.6876 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.66402\n",
            "Epoch 20/30\n",
            "9/9 - 4s - loss: 0.5129 - accuracy: 0.8395 - val_loss: 0.6536 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.66402 to 0.65360, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 21/30\n",
            "9/9 - 4s - loss: 0.4740 - accuracy: 0.8569 - val_loss: 0.6717 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.65360\n",
            "Epoch 22/30\n",
            "9/9 - 4s - loss: 0.4526 - accuracy: 0.8665 - val_loss: 0.6630 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.65360\n",
            "Epoch 23/30\n",
            "9/9 - 4s - loss: 0.4145 - accuracy: 0.8820 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.65360\n",
            "Epoch 24/30\n",
            "9/9 - 4s - loss: 0.4079 - accuracy: 0.8723 - val_loss: 0.6827 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.65360\n",
            "Epoch 25/30\n",
            "9/9 - 4s - loss: 0.3541 - accuracy: 0.9130 - val_loss: 0.6510 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.65360 to 0.65101, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 26/30\n",
            "9/9 - 4s - loss: 0.3501 - accuracy: 0.9091 - val_loss: 0.6741 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.65101\n",
            "Epoch 27/30\n",
            "9/9 - 4s - loss: 0.3232 - accuracy: 0.9149 - val_loss: 0.6604 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.65101\n",
            "Epoch 28/30\n",
            "9/9 - 4s - loss: 0.3133 - accuracy: 0.9149 - val_loss: 0.6683 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.65101\n",
            "Epoch 29/30\n",
            "9/9 - 4s - loss: 0.3025 - accuracy: 0.9168 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.65101 to 0.62527, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/wgt/intent1weights.hdf5\n",
            "Epoch 30/30\n",
            "9/9 - 4s - loss: 0.2694 - accuracy: 0.9381 - val_loss: 0.6525 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.62527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39591fa350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1JrFDf38SLW",
        "outputId": "c9be9eac-bd19-4601-99c4-8b5afde769ed"
      },
      "source": [
        "model_RCNNi1.save('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/saved_model/my_models1')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CCNNLSTM/saved_model/my_models1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZnSdpdG4yT"
      },
      "source": [
        "predicted = model_RCNNi1.predict(X_val)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_VoXCPRTDV"
      },
      "source": [
        "predicted = np.argmax(predicted, axis=1)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-09qtFOW0L"
      },
      "source": [
        " target_names = ['Asking for information', 'NAN', 'Providing information']"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Ubc6HjQaM6",
        "outputId": "7c3ad28a-5336-4c27-d3e2-6eb174435758"
      },
      "source": [
        "print(metrics.classification_report(np.argmax(y_test, axis=1), predicted , target_names=target_names))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "Asking for information       0.73      0.62      0.67        13\n",
            "                   NAN       1.00      0.71      0.83         7\n",
            " Providing information       0.78      0.89      0.83        28\n",
            "\n",
            "              accuracy                           0.79        48\n",
            "             macro avg       0.84      0.74      0.78        48\n",
            "          weighted avg       0.80      0.79      0.79        48\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJDIP-CRmtC"
      },
      "source": [
        "ans= np.array(['Asking for information', 'NAN', 'Providing information'])[predicted ]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLTvTL6CGnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109cb058-62ea-4bc1-c449-8ca10365df99"
      },
      "source": [
        "for x, y in zip(X_1, ans):\n",
        "  print(\"Chat body: \",x)\n",
        "  print(\"Predicted intent: \", y, \"\\n\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chat body:  My design depends on the piston diameter, what happens if you decrease it? \n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  Does increasing the flywheel thickness increase or decrease \"c\"?\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  That is what my document specifies. I will keep c low unless the piston needs it to be higher\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  thats if D = 45 where D is the piston bore diameter\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Does the flywheel shaft diameter \"ds\" affect any variables in your control?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  But if i increase the thickness i could make it a lot higher\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Increasing the offset increases the mass and decreases the factor of safety.\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Whats the effect of D on your results?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  can increase diameter is we need higher fos\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  Lower D, lowers my mass and FOS\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  whoever changed please go back\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  the 2.95 design also has the lowest mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  If that reduces your fos\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  no because it went down to fair, the mass went up a lot\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Have you changed the system at all? Our quality has dropped.\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  is there a bore diameter you are set on? or are you still experimenting?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  I just got my mass down to 0.11\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I am getting around 2.26-2.95\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Make sure you dont drop too much mass though\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  is that best case or worst case? my numbers are in the hundreds so we can play with ds if you use that\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  do you think I should try and increase those?\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  tf = 10 mm; ds = 25 mm;\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we should try a safe configuration and trim weight from there\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we have excellent quality right now\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  i think we have excellent quality right now\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Rn were under mass so if you need to you could increase it a bit\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Right now our factor of safety is chilling around 2.5\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I'm still seeing 'poor' on my end\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we're only trying to keep FOS over 2 right?\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  what range of fos #s are you getting? mine are in the hundreds so it's not the limiting system\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Yeah, that was nice\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  we're back to very good\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  back to very good\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  ya'' should chat about that\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  alright, guess not then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  okay\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  alright, guess no then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  before uploading any new broadcasts copy and paste a message into all your chats so we know its changing\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Mine should be broadcasting\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  27\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  any FOS higher than 2 gets us nothing more, we need to drop mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  If I reduce my mass by .03, it reduces FOS by .25 to 1.76\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I now have minimum fos but i further decreased my mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Can you cut any more mass out and get closer to FOS  = 2\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  I think I optimized mine as well my mass is at 0.10 and fos is 2.77\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  for tf = 10 & ds = 25; m = 0.55 and FOS = 5625.56\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  the current broadcast. FOS = 5626\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  tf = 10, ds = 25\n",
            "Predicted intent:  Providing information \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}