{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAR CNN-BDLSTM_M1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guott3kGTrxa",
        "outputId": "6b594115-7104-4986-903d-9e1cd14b4e5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOnWJ1hrEDYz"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras import initializers, regularizers, optimizers, layers\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OArVbJGpFtsE"
      },
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_chars=150,MAX_SEQUENCE_LENGTH=200):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "\n",
        "    alphabet=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "    char_dict = {}\n",
        "    for i, char in enumerate(alphabet):\n",
        "      char_dict[char] = i + 1\n",
        "    \n",
        "    print(\"characters of the dictionary are  \")\n",
        "    print(char_dict)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_chars, char_level=True, oov_token='UNK')\n",
        "    # Use char_dict to replace the tk.word_index\n",
        "    tokenizer.word_index = char_dict \n",
        "    # Add 'UNK' to the vocabulary \n",
        "    tokenizer.word_index[tokenizer.oov_token] = max(char_dict.values()) + 1\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    vocab_size = len(tokenizer.word_index)+1\n",
        "\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    return (X_train, X_test, word_index,vocab_size)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8lZ3R3_Ge5y"
      },
      "source": [
        "def Build_Model_RCNN_Text(word_index, nclasses, VS, MAX_SEQUENCE_LENGTH=200, EMBEDDING_DIM=100):\n",
        "\n",
        "    kernel_size = 4\n",
        "    filters = 100\n",
        "    pool_size = 4\n",
        "    gru_node = 128\n",
        "\n",
        "    embed_size = EMBEDDING_DIM\n",
        "    embedding_layer = Embedding(VS, embed_size, input_length=MAX_SEQUENCE_LENGTH, trainable=True)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Conv1D(filters=100, kernel_size=5,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=100, kernel_size=4,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=100, kernel_size=3,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.3,recurrent_dropout=0.5)))\n",
        "    #model.add(Bidirectional(LSTM(128, return_sequences=True,name='lstm_layer',dropout=0.4,recurrent_dropout=0.5)))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(units=512, activation=\"relu\",\n",
        "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "    bias_regularizer=regularizers.l2(1e-4),\n",
        "    activity_regularizer=regularizers.l2(1e-5)))\n",
        "    model.add(Dropout(rate=0.4))\n",
        "    model.add(Dense(3, activation=\"softmax\"))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-7,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\")\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer= opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MbmBziSXghA"
      },
      "source": [
        "def get_data_train():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/trainset_int1.csv')\n",
        "  df.head()\n",
        "  X=df['body']\n",
        "  Y = df['intent_1'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  Y = to_categorical(Y_nids, num_classes=3)\n",
        "  return X, Y"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAB1J1yBqcCk"
      },
      "source": [
        "def get_data_test():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data_i1.csv')\n",
        "  df.head()\n",
        "  X_t = df['body']\n",
        "  Y = df['intent_1'].astype(\"category\")\n",
        "  cat_types= Y.cat.categories\n",
        "  Y_nids = Y.cat.codes\n",
        "  y_t = to_categorical(Y_nids, num_classes=3)\n",
        "  return X_t, y_t"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uts74FvlRwJq"
      },
      "source": [
        " df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/Data_Aug/Validation_data_i1.csv')\n",
        " df.head()\n",
        " X_1 = df['body']\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt4R19XuGsx0",
        "outputId": "b5e080dc-cf56-4858-fdc9-cb38d0ac225d"
      },
      "source": [
        "#X_train, X_test1, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train,y_train= get_data_train()\n",
        "X_test1,y_test= get_data_test()\n",
        "X_train,X_test, word_index, vocab_size = loadData_Tokenizer(X_train,X_test1)\n",
        "nclasses=3\n",
        "\n",
        "model_CharRCNN = Build_Model_RCNN_Text(word_index, nclasses,vocab_size)\n",
        "\n",
        "\n",
        "model_CharRCNN.summary()\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "characters of the dictionary are  \n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, '0': 53, '1': 54, '2': 55, '3': 56, '4': 57, '5': 58, '6': 59, '7': 60, '8': 61, '9': 62, '-': 86, ',': 64, ';': 65, '.': 66, '!': 67, '?': 68, ':': 69, \"'\": 70, '\"': 71, '/': 72, '\\\\': 73, '|': 74, '_': 75, '@': 76, '#': 77, '$': 78, '%': 79, '^': 80, '&': 81, '*': 82, '~': 83, '`': 84, '+': 85, '=': 87, '<': 88, '>': 89, '(': 90, ')': 91, '[': 92, ']': 93, '{': 94, '}': 95}\n",
            "Found 57 unique tokens.\n",
            "(565, 200)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 200, 100)          5800      \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 200, 100)          50100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 100, 100)          40100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 50, 100)           30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 25, 256)           234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 493,719\n",
            "Trainable params: 493,719\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujDz5F_iGx6m",
        "outputId": "e5c4b4cb-b1e5-4c11-8c5f-c10ab01a1621"
      },
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "model_CharRCNN.fit(X_train, y_train,\n",
        "                              validation_data=(X_test,y_test),\n",
        "                              epochs=40,\n",
        "                              batch_size=64,\n",
        "                              verbose=2, callbacks=[checkpointer])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/40\n",
            "9/9 - 9s - loss: 1.1567 - accuracy: 0.5667 - val_loss: 1.1024 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.10235, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 2/40\n",
            "9/9 - 3s - loss: 1.0300 - accuracy: 0.5919 - val_loss: 1.0339 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.10235 to 1.03387, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 3/40\n",
            "9/9 - 3s - loss: 0.9851 - accuracy: 0.5919 - val_loss: 1.0046 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.03387 to 1.00458, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 4/40\n",
            "9/9 - 3s - loss: 0.9662 - accuracy: 0.5919 - val_loss: 0.9949 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.00458 to 0.99491, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 5/40\n",
            "9/9 - 3s - loss: 0.9444 - accuracy: 0.5919 - val_loss: 0.9725 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.99491 to 0.97247, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 6/40\n",
            "9/9 - 3s - loss: 0.9280 - accuracy: 0.5919 - val_loss: 0.9593 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.97247 to 0.95926, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 7/40\n",
            "9/9 - 3s - loss: 0.9197 - accuracy: 0.5919 - val_loss: 0.9514 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.95926 to 0.95143, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 8/40\n",
            "9/9 - 3s - loss: 0.9048 - accuracy: 0.5919 - val_loss: 0.9378 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.95143 to 0.93782, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 9/40\n",
            "9/9 - 3s - loss: 0.9093 - accuracy: 0.5919 - val_loss: 0.9274 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.93782 to 0.92741, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 10/40\n",
            "9/9 - 3s - loss: 0.8889 - accuracy: 0.5919 - val_loss: 0.9153 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.92741 to 0.91533, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 11/40\n",
            "9/9 - 3s - loss: 0.8835 - accuracy: 0.5919 - val_loss: 0.8974 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.91533 to 0.89737, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 12/40\n",
            "9/9 - 3s - loss: 0.8727 - accuracy: 0.5957 - val_loss: 0.8867 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.89737 to 0.88668, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 13/40\n",
            "9/9 - 3s - loss: 0.8601 - accuracy: 0.6151 - val_loss: 0.8682 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.88668 to 0.86819, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 14/40\n",
            "9/9 - 3s - loss: 0.8594 - accuracy: 0.6228 - val_loss: 0.8582 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.86819 to 0.85823, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 15/40\n",
            "9/9 - 3s - loss: 0.8220 - accuracy: 0.6190 - val_loss: 0.8361 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.85823 to 0.83610, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 16/40\n",
            "9/9 - 3s - loss: 0.8161 - accuracy: 0.6286 - val_loss: 0.8197 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.83610 to 0.81972, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 17/40\n",
            "9/9 - 3s - loss: 0.8037 - accuracy: 0.6286 - val_loss: 0.8017 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.81972 to 0.80166, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 18/40\n",
            "9/9 - 3s - loss: 0.7847 - accuracy: 0.6460 - val_loss: 0.7920 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.80166 to 0.79199, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 19/40\n",
            "9/9 - 3s - loss: 0.7664 - accuracy: 0.6402 - val_loss: 0.7888 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.79199 to 0.78884, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 20/40\n",
            "9/9 - 3s - loss: 0.7410 - accuracy: 0.6557 - val_loss: 0.7753 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.78884 to 0.77531, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 21/40\n",
            "9/9 - 3s - loss: 0.6977 - accuracy: 0.7273 - val_loss: 0.7618 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.77531 to 0.76181, saving model to /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/CharCRNN/wgt/weights.hdf5\n",
            "Epoch 22/40\n",
            "9/9 - 3s - loss: 0.6724 - accuracy: 0.7485 - val_loss: 0.7912 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.76181\n",
            "Epoch 23/40\n",
            "9/9 - 3s - loss: 0.6306 - accuracy: 0.7485 - val_loss: 0.8151 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.76181\n",
            "Epoch 24/40\n",
            "9/9 - 3s - loss: 0.6293 - accuracy: 0.7485 - val_loss: 0.8229 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.76181\n",
            "Epoch 25/40\n",
            "9/9 - 3s - loss: 0.5729 - accuracy: 0.7911 - val_loss: 0.8487 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.76181\n",
            "Epoch 26/40\n",
            "9/9 - 3s - loss: 0.5636 - accuracy: 0.7892 - val_loss: 0.8587 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.76181\n",
            "Epoch 27/40\n",
            "9/9 - 3s - loss: 0.5336 - accuracy: 0.8143 - val_loss: 0.8432 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.76181\n",
            "Epoch 28/40\n",
            "9/9 - 3s - loss: 0.6141 - accuracy: 0.7679 - val_loss: 0.8633 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.76181\n",
            "Epoch 29/40\n",
            "9/9 - 3s - loss: 0.5674 - accuracy: 0.7988 - val_loss: 0.8585 - val_accuracy: 0.7292\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.76181\n",
            "Epoch 30/40\n",
            "9/9 - 3s - loss: 0.4981 - accuracy: 0.8511 - val_loss: 0.8843 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.76181\n",
            "Epoch 31/40\n",
            "9/9 - 3s - loss: 0.4775 - accuracy: 0.8511 - val_loss: 0.8872 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.76181\n",
            "Epoch 32/40\n",
            "9/9 - 3s - loss: 0.4583 - accuracy: 0.8549 - val_loss: 0.9466 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.76181\n",
            "Epoch 33/40\n",
            "9/9 - 3s - loss: 0.4341 - accuracy: 0.8453 - val_loss: 0.9742 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.76181\n",
            "Epoch 34/40\n",
            "9/9 - 3s - loss: 0.4578 - accuracy: 0.8395 - val_loss: 0.9064 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.76181\n",
            "Epoch 35/40\n",
            "9/9 - 3s - loss: 0.3576 - accuracy: 0.9033 - val_loss: 0.9467 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.76181\n",
            "Epoch 36/40\n",
            "9/9 - 3s - loss: 0.3264 - accuracy: 0.9091 - val_loss: 1.0022 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.76181\n",
            "Epoch 37/40\n",
            "9/9 - 3s - loss: 0.3322 - accuracy: 0.8994 - val_loss: 1.0142 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.76181\n",
            "Epoch 38/40\n",
            "9/9 - 3s - loss: 0.2925 - accuracy: 0.9188 - val_loss: 1.0315 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.76181\n",
            "Epoch 39/40\n",
            "9/9 - 3s - loss: 0.3801 - accuracy: 0.8588 - val_loss: 0.9337 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.76181\n",
            "Epoch 40/40\n",
            "9/9 - 3s - loss: 0.2674 - accuracy: 0.9420 - val_loss: 0.9541 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.76181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3f244cdd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1JrFDf38SLW",
        "outputId": "d2a4cb45-d8ea-4deb-ae92-76ff1db21932"
      },
      "source": [
        "model_CharRCNN.save('/content/drive/MyDrive/Colab Notebooks/Data/Engine_design/model_CharCRNN/saved_model/my_models1')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Data/Engine_design/model_CharCRNN/saved_model/my_models1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZnSdpdG4yT"
      },
      "source": [
        "predicted = model_CharRCNN.predict(X_test)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_VoXCPRTDV"
      },
      "source": [
        "predicted = np.argmax(predicted, axis=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-09qtFOW0L"
      },
      "source": [
        " target_names = ['Asking for information', 'NAN', 'Providing information']"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Ubc6HjQaM6",
        "outputId": "ed73dce9-d7d1-4bde-f866-0bb6ba5d8085"
      },
      "source": [
        "print(metrics.classification_report(np.argmax(y_test, axis=1), predicted , target_names=target_names))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "Asking for information       0.60      0.46      0.52        13\n",
            "                   NAN       0.62      0.71      0.67         7\n",
            " Providing information       0.73      0.79      0.76        28\n",
            "\n",
            "              accuracy                           0.69        48\n",
            "             macro avg       0.65      0.65      0.65        48\n",
            "          weighted avg       0.68      0.69      0.68        48\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJDIP-CRmtC"
      },
      "source": [
        "ans= np.array(['Asking for information', 'NAN', 'Providing information'])[predicted ]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLTvTL6CGnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f4a6ab-83ab-4b50-a3c1-0b3a54ed6c15"
      },
      "source": [
        "for x, y in zip(X_1, ans):\n",
        "  print(\"Chat body: \",x)\n",
        "  print(\"Predicted intent: \", y, \"\\n\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chat body:  My design depends on the piston diameter, what happens if you decrease it? \n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Does increasing the flywheel thickness increase or decrease \"c\"?\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  That is what my document specifies. I will keep c low unless the piston needs it to be higher\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  thats if D = 45 where D is the piston bore diameter\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Does the flywheel shaft diameter \"ds\" affect any variables in your control?\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  But if i increase the thickness i could make it a lot higher\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Increasing the offset increases the mass and decreases the factor of safety.\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  Whats the effect of D on your results?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  can increase diameter is we need higher fos\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  Lower D, lowers my mass and FOS\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  whoever changed please go back\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  the 2.95 design also has the lowest mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  If that reduces your fos\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  no because it went down to fair, the mass went up a lot\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Have you changed the system at all? Our quality has dropped.\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  is there a bore diameter you are set on? or are you still experimenting?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  I just got my mass down to 0.11\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I am getting around 2.26-2.95\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Make sure you dont drop too much mass though\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  is that best case or worst case? my numbers are in the hundreds so we can play with ds if you use that\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  do you think I should try and increase those?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  tf = 10 mm; ds = 25 mm;\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we should try a safe configuration and trim weight from there\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we have excellent quality right now\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  i think we have excellent quality right now\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Rn were under mass so if you need to you could increase it a bit\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Right now our factor of safety is chilling around 2.5\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  I'm still seeing 'poor' on my end\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  we're only trying to keep FOS over 2 right?\n",
            "Predicted intent:  Asking for information \n",
            "\n",
            "Chat body:  what range of fos #s are you getting? mine are in the hundreds so it's not the limiting system\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Yeah, that was nice\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  we're back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  back to very good\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  ya'' should chat about that\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  alright, guess not then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  okay\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  alright, guess no then\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  before uploading any new broadcasts copy and paste a message into all your chats so we know its changing\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Mine should be broadcasting\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  27\n",
            "Predicted intent:  NAN \n",
            "\n",
            "Chat body:  any FOS higher than 2 gets us nothing more, we need to drop mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  If I reduce my mass by .03, it reduces FOS by .25 to 1.76\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I now have minimum fos but i further decreased my mass\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  Can you cut any more mass out and get closer to FOS  = 2\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  I think I optimized mine as well my mass is at 0.10 and fos is 2.77\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  for tf = 10 & ds = 25; m = 0.55 and FOS = 5625.56\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  the current broadcast. FOS = 5626\n",
            "Predicted intent:  Providing information \n",
            "\n",
            "Chat body:  tf = 10, ds = 25\n",
            "Predicted intent:  Providing information \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}