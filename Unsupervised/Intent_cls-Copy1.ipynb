{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROSg9T9EzYDf"
   },
   "source": [
    "# Intent Recognition with BERT using Keras and TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zCRkokr-n26J"
   },
   "outputs": [],
   "source": [
    "!pip install tqdm  >> /dev/null\n",
    "!pip install bert-for-tf2 >> /dev/null\n",
    "!pip install sentencepiece >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VLPwBaua6jf2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzkSXum8RzGM"
   },
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eL2BmRgYIZkl",
    "outputId": "6de1ed0f-e9d4-4013-eeea-c5e557abccf4"
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1OlcvGWReJMuyYQuOZm149vHWwPtlboR6 --output train.csv\n",
    "# !gdown --id 1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w --output valid.csv\n",
    "# !gdown --id 1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF --output test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RNKtsTSTPhh",
    "outputId": "89d349c5-78eb-4a3e-b533-d3dfdff3e5b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "train = pd.read_csv(\"Designintent1_train.csv\")\n",
    "valid = pd.read_csv(\"Designintent1_valid.csv\")\n",
    "test = pd.read_csv(\"Designintent1_test.csv\")\n",
    "\n",
    "train = train.append(valid).reset_index(drop = True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "i4cZ4oi_TTfC",
    "outputId": "ee96b3eb-dbd9-433f-f958-4b2a35133b40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>intent_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi piston! My crankshaft depends on your bore ...</td>\n",
       "      <td>Providing information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank you!</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How low can you go on the piston bore diameter?</td>\n",
       "      <td>Asking for information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all my fos values are in the hundreds, i suspe...</td>\n",
       "      <td>Asking for information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi flywheel! My crankshaft depends on your fly...</td>\n",
       "      <td>Providing information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body                intent_1\n",
       "0  Hi piston! My crankshaft depends on your bore ...   Providing information\n",
       "1                                         thank you!                     NAN\n",
       "2    How low can you go on the piston bore diameter?  Asking for information\n",
       "3  all my fos values are in the hundreds, i suspe...  Asking for information\n",
       "4  Hi flywheel! My crankshaft depends on your fly...   Providing information"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc23faMAR--V"
   },
   "source": [
    "# Intent Recognition with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-P2y2g3m8Ytp",
    "outputId": "39f86924-d28f-4344-b651-1dfd954b3b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARivu75M8fqM",
    "outputId": "a821f064-ac08-4aac-cd8e-bae61e24272e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open uncased_L-12_H-768_A-12.zip, uncased_L-12_H-768_A-12.zip.zip or uncased_L-12_H-768_A-12.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4Cgl9mvs8hAl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: rename uncased_L-12_H-768_A-12/ to model/uncased_L-12_H-768_A-12/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"model\", exist_ok = True)\n",
    "!mv uncased_L-12_H-768_A-12/ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LbvjbsEb9Ndv"
   },
   "outputs": [],
   "source": [
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    "\n",
    "bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
    "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3os6qeC6SB-M"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TApTW_wLxoA9"
   },
   "outputs": [],
   "source": [
    "class IntentDetectionData:\n",
    "  DATA_COLUMN = \"text\"\n",
    "  LABEL_COLUMN = \"intent\"\n",
    "\n",
    "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_seq_len = 0\n",
    "    self.classes = classes\n",
    "    \n",
    "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
    "\n",
    "    print(\"max seq_len\", self.max_seq_len)\n",
    "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
    "\n",
    "  def _prepare(self, df):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "      text, label = row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
    "      tokens = self.tokenizer.tokenize(text)\n",
    "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "      x.append(token_ids)\n",
    "      y.append(self.classes.index(label))\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "  def _pad(self, ids):\n",
    "    x = []\n",
    "    for input_ids in ids:\n",
    "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "      x.append(np.array(input_ids))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQWpVG464BuO",
    "outputId": "664b26db-a078-470d-87f8-d33aa52a3a9c"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "model/uncased_L-12_H-768_A-12/vocab.txt; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-64df325c2206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_ckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vocab.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I can't wait to visit Bulgaria again!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/bert/tokenization/bert_tokenization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/bert/tokenization/bert_tokenization.py\u001b[0m in \u001b[0;36mload_vocab\u001b[0;34m(vocab_file)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;34mr\"\"\"Reads the next line, keeping \\n. At EOF, returns ''.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         raise errors.PermissionDeniedError(None, None,\n\u001b[1;32m     77\u001b[0m                                            \"File isn't open for reading\")\n\u001b[0;32m---> 78\u001b[0;31m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0m\u001b[1;32m     79\u001b[0m           self.__name, 1024 * 512)\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: model/uncased_L-12_H-768_A-12/vocab.txt; No such file or directory"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
    "\n",
    "tokenizer.tokenize(\"I can't wait to visit Bulgaria again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVz4kjcXHnnM",
    "outputId": "67f8a917-f1ae-4077-ed21-c0af668c233f"
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(\"I can't wait to visit Bulgaria again!\")\n",
    "tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnGGC53P9nC8"
   },
   "outputs": [],
   "source": [
    "def create_model(max_seq_len, bert_ckpt_file):\n",
    "\n",
    "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "      bc = StockBertConfig.from_json_string(reader.read())\n",
    "      bert_params = map_stock_config_to_params(bc)\n",
    "      bert_params.adapter_size = None\n",
    "      bert = BertModelLayer.from_params(bert_params, name = \"bert\")\n",
    "        \n",
    "  input_ids = keras.layers.Input(shape = (max_seq_len, ), dtype = 'int32', name = \"input_ids\")\n",
    "  bert_output = bert(input_ids)\n",
    "\n",
    "  print(\"bert shape\", bert_output.shape)\n",
    "\n",
    "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
    "  logits = keras.layers.Dense(units = 768, activation = \"tanh\")(cls_out)\n",
    "  logits = keras.layers.Dropout(0.5)(logits)\n",
    "  logits = keras.layers.Dense(units = len(classes), activation = \"softmax\")(logits)\n",
    "\n",
    "  model = keras.Model(inputs = input_ids, outputs = logits)\n",
    "  model.build(input_shape = (None, max_seq_len))\n",
    "\n",
    "  load_stock_weights(bert, bert_ckpt_file)\n",
    "        \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67GbMH3WRvZg"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXyaQY4E9S10",
    "outputId": "5a48c740-38a8-4434-848a-292f2e12fb0e"
   },
   "outputs": [],
   "source": [
    "classes = train.intent.unique().tolist()\n",
    "\n",
    "data = IntentDetectionData(train, test, tokenizer, classes, max_seq_len = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kZxXxEcdRnI",
    "outputId": "d69b26ae-bbcc-46e0-9faa-48ba60816159"
   },
   "outputs": [],
   "source": [
    "data.train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pilJksXUcsbq",
    "outputId": "ad0fcbca-37b4-41b2-8bd5-cea006cbcc9f"
   },
   "outputs": [],
   "source": [
    "data.train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TizDFiPC9n4b",
    "outputId": "7c2c40d1-92d4-4dbb-b6f0-7396832e6def"
   },
   "outputs": [],
   "source": [
    "model = create_model(data.max_seq_len, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjUkMjiGbC7f",
    "outputId": "dc4710f8-c175-4668-e4c4-0b4ef6d233bf"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYEHNOvbU9o8"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer = keras.optimizers.Adam(1e-5),\n",
    "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = [keras.metrics.SparseCategoricalAccuracy(name = \"acc\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIjlbG8u9xis",
    "outputId": "99fd95c8-a2be-48ea-9573-07bffaff57b8"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  x=data.train_x, \n",
    "  y=data.train_y,\n",
    "  validation_split = 0.1,\n",
    "  batch_size = 16,\n",
    "  shuffle = True,\n",
    "  epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s31ZIADSGNp"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "5XLlcuVC1lLE",
    "outputId": "9160b63d-bb0b-483d-d0fb-bdbaf6aff3d8"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.title('Loss over training epochs')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "yZ7CVW_71m0Q",
    "outputId": "56321ff9-30aa-430b-b1c6-dfa2e3920671"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.plot(history.history['acc'])\n",
    "ax.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.title('Accuracy over training epochs')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGAECSj4AiD1",
    "outputId": "5787a32f-cc7b-47eb-f3a6-03e999f1c2ce"
   },
   "outputs": [],
   "source": [
    "_, train_acc = model.evaluate(data.train_x, data.train_y)\n",
    "_, test_acc = model.evaluate(data.test_x, data.test_y)\n",
    "\n",
    "print(\"train acc\", train_acc)\n",
    "print(\"test acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Leg5atNmPzGb"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(data.test_x).argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZYriKx6UUOb",
    "outputId": "f97f49bc-f8f3-4699-ff33-32e25a9540b9"
   },
   "outputs": [],
   "source": [
    "print(classification_report(data.test_y, y_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS-5TbGDP4rr"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(data.test_y, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index = classes, columns = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "DgkPl9gLS4DL",
    "outputId": "bca6bea6-9a6a-4da6-8099-f1d2f8c2d852"
   },
   "outputs": [],
   "source": [
    "hmap = sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation = 0, ha = 'right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation = 30, ha = 'right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pagHJ7JL06f"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"Play my favourite song right now on the player. I haven't listened the song from many days\",\n",
    "  \"Rate this book as awful because the content of this book is really horrible\",\n",
    "  \"Can someone tell me the temperature of Delhi. I am shivering even in 3 layers.\",\n",
    "  \"I am too much hungry. Can we go to restaurant for eating. I can't wait for long.\",\n",
    "  \"I wrote this new book could you take a second to rate it?\",\n",
    "  \"I love the mood, lets play some good songs\",\n",
    "  \"I am starving, let's eat outside already\",\n",
    "  \"Let me check how cold it is outside\",\n",
    "  \"lets put on some songs, any suggestions?\",\n",
    "  \"play the one you played last night\",\n",
    "  \"Let me add play that song next\",\n",
    "  \"check this artwork out\",\n",
    "  \"where is that movie playing? Is it even still playing?\",\n",
    "  \"Let's eat some waffles outside!\",\n",
    "  \"This book needs a lot of feedback\",\n",
    "  \"I want to watch that movie\",\n",
    "  \"The dal is very cold\",\n",
    "  \"Where is that art mueseum\",\n",
    "  \"Who made this painting?\",\n",
    "  \"The art is done by kadinsky isnt it?\",\n",
    "  \"Help me buy this book\",\n",
    "  \"lets but this earphones\",\n",
    "  \"I need motivation to write a book\"\n",
    "]\n",
    "\n",
    "pred_tokens = map(tokenizer.tokenize, sentences)\n",
    "pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    "\n",
    "pred_token_ids = map(lambda tids: tids + [0] * (data.max_seq_len-len(tids)), pred_token_ids)\n",
    "pred_token_ids = np.array(list(pred_token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Feyo0ULAmEW",
    "outputId": "24daa9b3-806e-47f7-b9d4-7b6feb4587bd"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(pred_token_ids).argmax(axis = -1)\n",
    "\n",
    "for text, label in zip(sentences, predictions):\n",
    "  print(\"text:\", text, \"\\nintent:\", classes[label])\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Intent_cls.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
